# MATH Benchmark Test Configuration (Standalone Version)
model:
  path: microsoft/DialoGPT-small  # Small model for testing
  trust_remote_code: false

data:
  dataset_name: DigitalLearningGmbH/MATH-lighteval
  split: test
  max_samples: 3  # Very small for testing
  
rollout:
  name: vllm
  mode: sync
  temperature: 1.0
  top_k: -1
  top_p: 0.95
  max_tokens: 256  # Smaller for testing
  dtype: float16
  gpu_memory_utilization: 0.7
  enforce_eager: true
  free_cache_engine: true
  tensor_model_parallel_size: 1
  max_num_batched_tokens: 4096
  disable_log_stats: true
  enable_chunked_prefill: false

output:
  results_file: test_results.json
  batch_size: 2  # Small batch for testing
  
device:
  device_name: cuda
  world_size: 1 